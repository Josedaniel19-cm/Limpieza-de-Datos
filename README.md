# Limpieza-de-Datos
Hecho por: Jose Daniel Cabarcas Mass

1. Contexto general

En todo proceso de análisis de datos, la etapa de limpieza y preparación de la información es una de las más críticas y determinantes para el éxito del proyecto. Los datos reales rara vez se encuentran organizados o listos para analizar; con frecuencia presentan valores faltantes, duplicados, inconsistencias, errores de formato o información irrelevante. Por ello, antes de aplicar modelos estadísticos o de aprendizaje automático, es fundamental asegurar la calidad, coherencia y completitud de los datos.

Este trabajo tiene como finalidad aplicar las técnicas de limpieza de datos aprendidas en clase utilizando un conjunto de datos real. A través de un proceso sistemático, se busca identificar problemas comunes en la información, corregirlos y preparar el dataset para un análisis más profundo o para futuras etapas del flujo de trabajo en ciencia de datos.

2. Propósito del trabajo

El propósito de este trabajo es que el estudiante desarrolle habilidades prácticas en la detección, diagnóstico y corrección de problemas en los datos, aplicando buenas prácticas de preprocesamiento con herramientas del ecosistema Python.
De esta forma, el estudiante comprenderá que la limpieza no es una etapa trivial, sino una fase esencial para garantizar resultados válidos, reproducibles y de calidad en el análisis posterior.

3. Objetivos
Objetivo general

Aplicar técnicas de limpieza y preparación de datos a un dataset real, identificando al menos cinco problemáticas que requieran intervención para mejorar la calidad del conjunto de datos.

Objetivos específicos

Cargar e inspeccionar la estructura del dataset seleccionado.

Identificar valores nulos, duplicados e inconsistencias.

Analizar los tipos de datos de cada variable y corregir errores de formato.

Estandarizar nombres, unidades y categorías.

Detectar y manejar valores atípicos o inconsistentes.

Generar una versión limpia y lista para análisis posterior.

4. Metodología

El trabajo se realizará empleando el lenguaje Python y librerías específicas para el tratamiento de datos, entre ellas:

Pandas: para la manipulación, transformación y análisis tabular.

NumPy: para operaciones numéricas y manejo de matrices.

Matplotlib / Seaborn: para la visualización de patrones e inconsistencias.

El procedimiento general incluirá las siguientes etapas:

Carga del dataset seleccionado desde Kaggle o una fuente alternativa.

Exploración inicial: descripción general de las variables, conteo de valores y tipos de datos.

Detección de problemas: búsqueda de nulos, duplicados, valores fuera de rango, formatos incorrectos, entre otros.

Tratamiento y corrección: imputación de valores, eliminación o sustitución de datos erróneos, ajuste de formatos.

Estandarización: homogeneización de categorías y normalización de nombres o unidades.

Validación final: comprobación de la consistencia del dataset limpio.

5. Importancia del trabajo

La limpieza de datos es una de las competencias más demandadas en el ámbito de la ciencia de datos, la analítica empresarial y la investigación empírica. Un conjunto de datos limpio y estructurado no solo facilita la aplicación de técnicas estadísticas o de machine learning, sino que reduce errores, sesgos y conclusiones erróneas.

En este sentido, el trabajo permite que el estudiante comprenda la importancia de la calidad de los datos como base de cualquier análisis, reforzando la idea de que la limpieza es una parte integral del proceso y no un paso secundario.

6. Resultados esperados

Al finalizar el trabajo, el estudiante será capaz de:

Comprender la estructura y problemas comunes en datos reales.

Aplicar estrategias efectivas para el manejo de valores nulos, duplicados y atípicos.

Corregir inconsistencias de formato y tipo de dato.

Generar un dataset depurado, ordenado y listo para análisis o modelamiento.

Documentar adecuadamente el proceso de limpieza con comentarios claros y reproducibles.

7. Estructura del trabajo

El documento se divide en las siguientes secciones:

Carga y exploración inical de dataset.

Identificación de problemáticas.

Limpieza de datos paso a paso.

Verificación de la limpieza

Guardar dataset limpio.

Conclusiones.
